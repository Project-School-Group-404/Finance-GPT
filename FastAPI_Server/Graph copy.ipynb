{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cebc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Dict, List,Any\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage,AnyMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from IPython.display import Image,display\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# tools\n",
    "from Tools.Doc_QnA_RAG import rag_qa_tool\n",
    "from Tools.News import financial_news_search\n",
    "from Tools.general_qna import gen_qna\n",
    "from Tools.Image_qna import image_qna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f515960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict, total=False):\n",
    "    input: str\n",
    "    uploaded_doc : str\n",
    "    uploaded_img : str\n",
    "    agent_order: List[Dict[str,str]]\n",
    "    routing_reasoning : str      \n",
    "    current_agent_index : int\n",
    "    processed_agents : List[str]        \n",
    "    agent_outputs: Dict[str, str]       \n",
    "    final_response: str  \n",
    "    messages: List[AnyMessage]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797390c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model_name=\"llama-3.3-70b-versatile\",\n",
    "#     temperature=0.0,\n",
    "# )\n",
    "\n",
    "# llm = ChatGroq(\n",
    "#     model_name=\"gemma2-9b-it\",\n",
    "#     temperature=0.0,\n",
    "# )\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize the Llama 3.1 8B model with the custom endpoint\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    base_url=\"https://ollama-gcs-172789587838.us-central1.run.app\",\n",
    "    temperature=0.7\n",
    ")\n",
    "llm.invoke(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me a short story\"\n",
    "for chunk in llm.stream(query):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd74c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTER_PROMPT = \"\"\"\n",
    "You are a routing assistant that decomposes user queries into agent-specific sub-queries for a finance chatbot, using the query, conversation history, and available tools to determine execution order, dependencies, and whether the query is a follow-up.\n",
    "ONLY GIVE THE OUTPUT NOTHING ELSE \n",
    "Available Tools:\n",
    "1. Document_qna: Answers questions about uploaded documents (e.g., PDFs) using RAG. Requires a document ID from uploaded_docs.\n",
    "2. News: Fetches and analyzes recent financial news or events.\n",
    "3. Image_qna: Analyzes uploaded images (e.g., charts, tables).\n",
    "4. General_qna: Handles general finance or reasoning questions without documents or images.\n",
    "5. Summarizer: Synthesizes or summarizes prior tool outputs or responses, used for follow-ups (e.g., 'make it shorter').\n",
    "\n",
    "Inputs:\n",
    "- Query: The current user query.\n",
    "- Conversation history: JSON list of messages [{type: 'human'/'ai', content: str}].\n",
    "- Uploaded documents: JSON list of [path: str].\n",
    "- Uploaded image: Single path string or empty.\n",
    "\n",
    "Your Task:\n",
    "1. Analyze the query and history to identify intent, follow-ups, and referenced documents/images.\n",
    "2. Select the correct document/image from uploaded_docs or uploaded_img using doc_id or history context (e.g., 'document from earlier'). Default to the latest uploaded_docs/image if ambiguous.\n",
    "3. Decompose the query into sub-queries for relevant tools, ensuring each is clear and isolated.\n",
    "4. Specify execution order and dependencies (e.g., Document_qna may depend on News).\n",
    "5. For follow-ups (e.g., 'make it shorter', 'more details'), route to Summarizer with instructions to use history.\n",
    "6. For ambiguous queries not requiring tools, route to Summarizer to leverage history.\n",
    "7. Include 'doc_id' for Document_qna and 'img_id' for Image_qna in agent entries.\n",
    "\n",
    "\n",
    "Output Format:\n",
    "{\n",
    "    \"agents\": [\n",
    "        {\n",
    "            \"name\": \"Document_qna\",\n",
    "            \"query\": \"Specific query for document\",\n",
    "            \"dependencies\": []\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"News\",\n",
    "            \"query\": \"Specific query for news\",\n",
    "            \"dependencies\": []\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"General_qna\",\n",
    "            \"query\": \"Specific query for reasoning\",\n",
    "            \"dependencies\": [\"Document_qna\", \"News\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Image_qna\",\n",
    "            \"query\": \"Specific query for image\",\n",
    "            \"dependencies\": []\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Summarizer\",\n",
    "            \"query\": \"Synthesize or summarize outputs\",\n",
    "            \"dependencies\": [\"Document_qna\", \"News\"]\n",
    "        }\n",
    "    ],\n",
    "    \"reasoning\": \"Explain decomposition, document/image selection, and dependency logic\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- If no document/image is referenced and the query is ambiguous, route to Summarizer or General_qna.\n",
    "- If no tools are suitable (e.g., non-finance query), return an empty agents list.\n",
    "- For follow-ups, use history to identify prior outputs or context.\n",
    "- Ensure dependencies reflect logical order (e.g., News before Document_qna for policy impact).\n",
    "\n",
    "Examples:\n",
    "1. Query: \"What is the revenue in the document uploaded earlier?\"\n",
    "   History: [{\"type\": \"ai\", \"content\": \"Uploaded document: /doc1.pdf with ID doc1\", \"timestamp\": \"2025-07-16T10:00:00\"}]\n",
    "   Uploaded_docs: [{\"id\": \"doc1\", \"path\": \"/doc1.pdf\", \"timestamp\": \"2025-07-16T10:00:00\"}]\n",
    "   Output: {\n",
    "       \"agents\": [\n",
    "           {\n",
    "               \"name\": \"Document_qna\",\n",
    "               \"query\": \"What is the revenue according to the document?\",\n",
    "               \"dependencies\": []\n",
    "           }\n",
    "       ],\n",
    "       \"reasoning\": \"Query refers to 'document uploaded earlier', matched to doc1 in history.\"\n",
    "   }\n",
    "\n",
    "2. Query: \"How does the latest tax policy affect revenue in the new document?\"\n",
    "   History: [{\"type\": \"ai\", \"content\": \"Uploaded document: /doc2.pdf with ID doc2\"}]\n",
    "   Uploaded_docs: [{\"id\": \"doc1\", \"path\": \"/doc1.pdf\"}, {\"id\": \"doc2\", \"path\": \"/doc2.pdf\"}]\n",
    "   Output: {\n",
    "       \"agents\": [\n",
    "           {\n",
    "               \"name\": \"News\",\n",
    "               \"query\": \"What is the latest tax policy?\",\n",
    "               \"dependencies\": []\n",
    "           },\n",
    "           {\n",
    "               \"name\": \"Document_qna\",\n",
    "               \"query\": \"How does the latest tax policy affect revenue in the document?\",\n",
    "               \"dependencies\": [\"News\"]\n",
    "           }\n",
    "       ],\n",
    "       \"reasoning\": \"Query requires tax policy (News) and revenue impact (Document_qna) using latest document (doc2).\"\n",
    "   }\n",
    "\n",
    "3. Query: \"Make it shorter\"\n",
    "   History: [{\"type\": \"ai\", \"content\": \"Final response: Revenue is $4.9T...\"}]\n",
    "   Output: {\n",
    "       \"agents\": [\n",
    "           {\n",
    "               \"name\": \"Summarizer\",\n",
    "               \"query\": \"Summarize the previous response\",\n",
    "               \"dependencies\": []\n",
    "           }\n",
    "       ],\n",
    "       \"reasoning\": \"Follow-up query refers to prior response, routed to Summarizer.\"\n",
    "   }\n",
    "\n",
    "4. Query: \"What does this chart show?\"\n",
    "   Uploaded_img: \"/chart1.jpg\"\n",
    "   Output: {\n",
    "       \"agents\": [\n",
    "           {\n",
    "               \"name\": \"Image_qna\",\n",
    "               \"query\": \"Describe the content of the chart\",\n",
    "               \"dependencies\": []\n",
    "           }\n",
    "       ],\n",
    "       \"reasoning\": \"Query targets the uploaded image, routed to Image_qna.\"\n",
    "   }\n",
    "\n",
    "5. Query: \"Whatâ€™s the weather today?\"\n",
    "   Output: {\n",
    "       \"agents\": [],\n",
    "       \"reasoning\": \"Non-finance query, no suitable tools.\"\n",
    "   }\n",
    "\n",
    "6. Query: \"What does the old document say about taxes, and how does it relate to recent news?\"\n",
    "   History: [{\"type\": \"ai\", \"content\": \"Uploaded document: /doc1.pdf with ID doc1\"}, {\"type\": \"ai\", \"content\": \"Uploaded document: /doc2.pdf with ID doc2\"}]\n",
    "   Uploaded_docs: [{\"id\": \"doc1\", \"path\": \"/doc1.pdf\"}, {\"id\": \"doc2\", \"path\": \"/doc2.pdf\"}]\n",
    "   Output: {\n",
    "       \"agents\": [\n",
    "           {\n",
    "               \"name\": \"Document_qna\",\n",
    "               \"query\": \"What does the document say about taxes?\",\n",
    "               \"dependencies\": []\n",
    "           },\n",
    "           {\n",
    "               \"name\": \"News\",\n",
    "               \"query\": \"What are recent news updates on tax policies?\",\n",
    "               \"dependencies\": []\n",
    "           },\n",
    "           {\n",
    "               \"name\": \"Summarizer\",\n",
    "               \"query\": \"Relate the documentâ€™s tax information to recent news\",\n",
    "               \"dependencies\": [\"Document_qna\", \"News\"]\n",
    "           }\n",
    "       ],\n",
    "       \"reasoning\": \"Query references 'old document' (doc1 from history) for taxes and recent news, with Summarizer to combine outputs.\"\n",
    "   }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Router(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    try:\n",
    "        query = state[\"input\"]      \n",
    "\n",
    "        # print(\"query received\") \n",
    "        messages = [\n",
    "            SystemMessage(content=ROUTER_PROMPT),\n",
    "            HumanMessage(content=f\"Query: {query}\")\n",
    "        ]\n",
    "        # print(\"query structured\")\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        raw = response.content.strip()\n",
    "        if raw.startswith(\"```\"):\n",
    "            raw = re.sub(r\"^```[a-z]*\\n?\", \"\", raw)\n",
    "            raw = re.sub(r\"\\n?```$\", \"\", raw)\n",
    "\n",
    "        # print(response.content)\n",
    "        # print(\"response generated\")\n",
    "        parsed = json.loads(raw)\n",
    "        # parsed = json.loads(response.content)\n",
    "        # print(\"response parsed!\")\n",
    "        # print(parsed)\n",
    "        \n",
    "        agents = parsed.get(\"agents\", [\n",
    "            {\n",
    "            \"name\": \"General_qna\",\n",
    "            \"query\": f\"{query}\",\n",
    "            \"dependencies\": []\n",
    "        }\n",
    "        ])\n",
    "        reasoning = parsed.get(\"reasoning\", \"Default routing\")\n",
    "        \n",
    "        valid_agents = [agent for agent in agents]\n",
    "    \n",
    "        if not valid_agents:\n",
    "            valid_agents = [\n",
    "            {\n",
    "            \"name\": \"General_qna\",\n",
    "            \"query\": f\"{query}\",\n",
    "            \"dependencies\": []\n",
    "            }\n",
    "        ]\n",
    "        state[\"agent_order\"] = valid_agents\n",
    "        state[\"routing_reasoning\"] = reasoning\n",
    "        state[\"agent_outputs\"] = {}\n",
    "        state[\"processed_agents\"] = []\n",
    "        state[\"current_agent_index\"] = 0          \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Routing : {e}\")\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_agents(state:Dict[str,Any]) -> str:\n",
    "    agent_order = state.get(\"agent_order\",[{\n",
    "            \"name\": \"General_qna\",\n",
    "            \"query\": f\"{state[\"input\"]}\",\n",
    "            \"dependencies\": []\n",
    "            }])\n",
    "    \n",
    "    if \"current_agent_index\" not in state:\n",
    "        state[\"current_agent_index\"] = 0\n",
    "\n",
    "    current_index = state[\"current_agent_index\"]\n",
    "\n",
    "    if current_index<len(agent_order):\n",
    "        agent = agent_order[current_index][\"name\"]\n",
    "        print(f\"Routing to : {agent}, current index at: {current_index}\")\n",
    "        return agent\n",
    "    return 'Aggregator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Document_qna(state:Dict[str,Any]) -> Dict[str,Any]:\n",
    "    try:\n",
    "        query = state[\"agent_order\"][state[\"current_agent_index\"]][\"query\"]\n",
    "        dependencies_list = state[\"agent_order\"][state[\"current_agent_index\"]][\"dependencies\"]\n",
    "\n",
    "        if dependencies_list:\n",
    "            for dep in dependencies_list:\n",
    "                if dep in state[\"agent_outputs\"]:\n",
    "                    dep_output = state[\"agent_outputs\"][dep]\n",
    "                    query += f\" based on the following {dep} context: {dep_output}\"\n",
    "                else:\n",
    "                    print(f\"Dependency {dep} output not found in agent_outputs\")      \n",
    "\n",
    "        # print(query)\n",
    "        uploaded_doc_path = state[\"uploaded_doc\"]\n",
    "        # print(uploaded_doc_path)\n",
    "        result  = rag_qa_tool.invoke({\n",
    "            \"file_path\": uploaded_doc_path,\n",
    "            \"query\": query\n",
    "        })\n",
    "        # print(result)\n",
    "        state[\"agent_outputs\"][\"Doc_QnA\"] = result\n",
    "        state[\"processed_agents\"].append(\"Document_QnA\")\n",
    "        if state[\"current_agent_index\"] + 1 <= len(state[\"agent_order\"]):\n",
    "            state[\"current_agent_index\"] = state[\"current_agent_index\"] + 1 \n",
    "        else: \n",
    "            state[\"current_agent_index\"] = 0\n",
    "\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Document_qna output: {result}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Doc_QnA : {e}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f69560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def News(state:Dict[str,Any]) -> Dict[str,Any]:\n",
    "    try:\n",
    "        query = state[\"agent_order\"][state[\"current_agent_index\"]][\"query\"]\n",
    "        print(query)\n",
    "        dependencies_list = state[\"agent_order\"][state[\"current_agent_index\"]][\"dependencies\"]\n",
    "\n",
    "        if dependencies_list:\n",
    "            for dep in dependencies_list:\n",
    "                if dep in state[\"agent_outputs\"]:\n",
    "                    dep_output = state[\"agent_outputs\"][dep]\n",
    "                    query += f\" based on the following {dep} context: {dep_output}\"\n",
    "                else:\n",
    "                    print(f\"Dependency {dep} output not found in agent_outputs\")      \n",
    "\n",
    "\n",
    "        print(\"entering news tool\")\n",
    "        result = financial_news_search.invoke({\"query\" : query})\n",
    "        state[\"agent_outputs\"][\"News\"] = result\n",
    "        state[\"processed_agents\"].append(\"NEWS\")\n",
    "        if state[\"current_agent_index\"] + 1 < len(state[\"agent_order\"]):\n",
    "            state[\"current_agent_index\"] = state[\"current_agent_index\"] + 1 \n",
    "        else: \n",
    "            state[\"current_agent_index\"] = 0\n",
    "        state[\"messages\"].append(AIMessage(content=f\"News output: {result}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in News : {e}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def General_qna(state:Dict[str,Any]) -> Dict[str,Any]:\n",
    "    try:\n",
    "        query = state[\"agent_order\"][state[\"current_agent_index\"]][\"query\"]\n",
    "        dependencies_list = state[\"agent_order\"][state[\"current_agent_index\"]][\"dependencies\"]\n",
    "\n",
    "        if dependencies_list:\n",
    "            for dep in dependencies_list:\n",
    "                if dep in state[\"agent_outputs\"]:\n",
    "                    dep_output = state[\"agent_outputs\"][dep]\n",
    "                    query += f\" based on the following {dep} context: {dep_output}\"\n",
    "                else:\n",
    "                    print(f\"Dependency {dep} output not found in agent_outputs\")      \n",
    "\n",
    "        result = gen_qna.invoke({\"question\" : query})\n",
    "        state[\"agent_outputs\"][\"General_QnA\"] = result\n",
    "        state[\"processed_agents\"].append(\"General_QnA\")\n",
    "        if state[\"current_agent_index\"] + 1 <= len(state[\"agent_order\"]):\n",
    "            state[\"current_agent_index\"] = state[\"current_agent_index\"] + 1 \n",
    "        else: \n",
    "            state[\"current_agent_index\"] = 0\n",
    "        state[\"messages\"].append(AIMessage(content=f\"General_qna output: {result}\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in General_qna : {e}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e634d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_qna(state:Dict[str,Any]) -> Dict[str,Any]:\n",
    "    try:\n",
    "        query =state[\"agent_order\"][state[\"current_agent_index\"]][\"query\"]\n",
    "        dependencies_list = state[\"agent_order\"][state[\"current_agent_index\"]][\"dependencies\"]\n",
    "\n",
    "        if dependencies_list:\n",
    "            for dep in dependencies_list:\n",
    "                if dep in state[\"agent_outputs\"]:\n",
    "                    dep_output = state[\"agent_outputs\"][dep]\n",
    "                    query += f\" based on the following {dep} context: {dep_output}\"\n",
    "                else:\n",
    "                    print(f\"Dependency {dep} output not found in agent_outputs\")  \n",
    "    \n",
    "        # print(query)\n",
    "        uploaded_img = state[\"uploaded_img\"]\n",
    "        # print(uploaded_doc_path)\n",
    "        response = image_qna.invoke({\n",
    "            \"uploaded_file\": uploaded_img,\n",
    "            \"query\": query\n",
    "        })\n",
    "        state[\"agent_outputs\"][\"Image_qna\"] = response\n",
    "        state[\"processed_agents\"].append(\"Image_qna\")\n",
    "        if state[\"current_agent_index\"] + 1 <= len(state[\"agent_order\"]):\n",
    "            state[\"current_agent_index\"] = state[\"current_agent_index\"] + 1 \n",
    "        else: \n",
    "            state[\"current_agent_index\"] = 0\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Image_qna output: {response}\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Image_qna : {e}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95101f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aggregator(state:Dict[str,Any]) -> Dict[str,Any]:\n",
    "    try:\n",
    "        final_agent_outputs = state[\"agent_outputs\"]\n",
    "        routing_reasoning = state.get(\"routing_reasoning\", \"\")\n",
    "        initial_query = state[\"input\"]\n",
    "\n",
    "        if not final_agent_outputs:\n",
    "            state[\"final_response\"] = \"No agent outputs to aggregate.\"\n",
    "            return state\n",
    "        \n",
    "        if len(final_agent_outputs) == 1:\n",
    "            _,response = next(iter(final_agent_outputs.items()))\n",
    "            state[\"final_response\"] = response\n",
    "\n",
    "        else:\n",
    "            aggregation_prompt = f\"\"\"\n",
    "                        You are an expert output aggregator. Given the initial query , Combine the following responses into a coherent, comprehensive answer , also if needed take into consideration the previous converstation history to answer the initial_query.\n",
    "                        \n",
    "                        initial query : {initial_query}\n",
    "                        Routing reasoning: {routing_reasoning}\n",
    "                        \n",
    "                        Responses:\n",
    "                        {json.dumps(final_agent_outputs, indent=2)}\n",
    "\n",
    "                        Conversation history: {json.dumps([msg.dict() for msg in state[\"messages\"]], indent=2)}\n",
    "                        Create a unified response that integrates insights from all the responses and the conversation history if needed, while avoiding redundancy.\n",
    "            \n",
    "                        \"\"\"\n",
    "            messages = [\n",
    "                SystemMessage(content=\"You are an expert at synthesizing information from multiple sources.\"),\n",
    "                HumanMessage(content=aggregation_prompt)\n",
    "            ]\n",
    "            \n",
    "            response = llm(messages)\n",
    "            state[\"final_response\"] = response.content\n",
    "            state[\"messages\"].append(AIMessage(content=state[\"final_response\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Aggregation : {e}\")\n",
    "\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94db77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"Router\", Router)\n",
    "builder.add_node(\"Document_qna\", Document_qna)\n",
    "builder.add_node(\"General_qna\", General_qna)\n",
    "builder.add_node(\"News\", News)\n",
    "builder.add_node(\"Image_qna\", Image_qna)\n",
    "\n",
    "builder.add_node(\"Aggregator\", Aggregator)\n",
    "\n",
    "builder.set_entry_point(\"Router\")\n",
    "\n",
    "tool_names = [\"Document_qna\", \"General_qna\", \"News\",\"Image_qna\" ,\"Aggregator\"]\n",
    "\n",
    "routing_map = {\n",
    "    'Document_qna': 'Document_qna',\n",
    "    'General_qna': 'General_qna',\n",
    "    'News': 'News',\n",
    "    \"Image_qna\" : \"Image_qna\",\n",
    "    'Aggregator': 'Aggregator'\n",
    "}\n",
    "\n",
    "builder.add_conditional_edges(\"Router\", \n",
    "                              route_to_agents,\n",
    "                                routing_map)\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"Document_qna\", \n",
    "    route_to_agents, \n",
    "    {\n",
    "    \"General_qna\": \"General_qna\",\n",
    "    \"News\": \"News\",\n",
    "    \"Image_qna\" : \"Image_qna\",\n",
    "    \"Aggregator\": \"Aggregator\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_conditional_edges(\"General_qna\", \n",
    "    route_to_agents, \n",
    "    {\n",
    "    \"Document_qna\": \"Document_qna\",\n",
    "    \"News\": \"News\",\n",
    "    \"Image_qna\" : \"Image_qna\",\n",
    "    \"Aggregator\": \"Aggregator\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_conditional_edges(\"News\", \n",
    "    route_to_agents, \n",
    "    {\n",
    "    \"Document_qna\": \"Document_qna\",\n",
    "    \"General_qna\": \"General_qna\",\n",
    "    \"Image_qna\" : \"Image_qna\",\n",
    "    \"Aggregator\": \"Aggregator\"\n",
    "    }\n",
    ")\n",
    "builder.add_conditional_edges(\"Image_qna\", \n",
    "    route_to_agents, \n",
    "    {\n",
    "    \"Document_qna\": \"Document_qna\",\n",
    "    \"General_qna\": \"General_qna\",\n",
    "    \"News\": \"News\",\n",
    "    \"Aggregator\": \"Aggregator\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"Aggregator\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46402918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=\"what is blockchain? and tell me what the given image is?\"\n",
    "# initial_state = {\n",
    "#         \"input\": query,\n",
    "#         \"uploaded_doc\" : \"/home/saikrishnanair/Finance-GPT/2PageNvidia.pdf\",\n",
    "#         \"uploaded_img\" : \"/home/saikrishnanair/balancesheet.png\",\n",
    "#         \"agent_order\": [],\n",
    "#         \"routing_reasoning\" : \"\",\n",
    "#         \"current_agent_index\": 0,\n",
    "#         \"processed_agents\": [],\n",
    "#         \"agent_outputs\": {},\n",
    "#         \"final_response\": \"\",\n",
    "#         \"messages\" : []\n",
    "#     }\n",
    "\n",
    "# result = graph.invoke(initial_state)\n",
    "# import pprint\n",
    "# pprint.pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
